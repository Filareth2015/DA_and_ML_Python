{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная регрессия и стохастический градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание основано на материалах лекций по линейной регрессии и градиентному спуску. Вы будете прогнозировать выручку компании в зависимости от уровня ее инвестиций в рекламу по TV, в газетах и по радио."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вы научитесь:\n",
    "- решать задачу восстановления линейной регрессии\n",
    "- реализовывать стохастический градиентный спуск для ее настройки\n",
    "- решать задачу линейной регрессии аналитически"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение\n",
    "Линейная регрессия - один из наиболее хорошо изученных методов машинного обучения, позволяющий прогнозировать значения количественного признака в виде линейной комбинации прочих признаков с параметрами - весами модели. Оптимальные (в смысле минимальности некоторого функционала ошибки) параметры линейной регрессии можно найти аналитически с помощью нормального уравнения или численно с помощью методов оптимизации.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная регрессия использует простой функционал качества - среднеквадратичную ошибку. Мы будем работать с выборкой, содержащей 3 признака. Для настройки параметров (весов) модели решается следующая задача:\n",
    "$$\\Large \\frac{1}{\\ell}\\sum_{i=1}^\\ell{{((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}^2} \\rightarrow \\min_{w_0, w_1, w_2, w_3},$$\n",
    "где $x_{i1}, x_{i2}, x_{i3}$ - значения признаков $i$-го объекта, $y_i$ - значение целевого признака $i$-го объекта, $\\ell$ - число объектов в обучающей выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный спуск\n",
    "Параметры $w_0, w_1, w_2, w_3$, по которым минимизируется среднеквадратичная ошибка, можно находить численно с помощью градиентного спуска.\n",
    "Градиентный шаг для весов будет выглядеть следующим образом:\n",
    "$$\\Large w_0 \\leftarrow w_0 - \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}}$$\n",
    "$$\\Large w_j \\leftarrow w_j - \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{x_{ij}((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}},\\ j \\in \\{1,2,3\\}$$\n",
    "Здесь $\\eta$ - параметр, шаг градиентного спуска."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стохастический градиентный спуск\n",
    "Проблема градиентного спуска, описанного выше, в том, что на больших выборках считать на каждом шаге градиент по всем имеющимся данным может быть очень вычислительно сложно. \n",
    "В стохастическом варианте градиентного спуска поправки для весов вычисляются только с учетом одного случайно взятого объекта обучающей выборки:\n",
    "$$\\Large w_0 \\leftarrow w_0 - \\frac{2\\eta}{\\ell} {((w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}) - y_k)}$$\n",
    "$$\\Large w_j \\leftarrow w_j - \\frac{2\\eta}{\\ell} {x_{kj}((w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}) - y_k)},\\ j \\in \\{1,2,3\\},$$\n",
    "где $k$ - случайный индекс, $k \\in \\{1, \\ldots, \\ell\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нормальное уравнение \n",
    "Нахождение вектора оптимальных весов $w$ может быть сделано и аналитически.\n",
    "Мы хотим найти такой вектор весов $w$, чтобы вектор $y$, приближающий целевой признак, получался умножением матрицы $X$ (состоящей из всех признаков объектов обучающей выборки, кроме целевого) на вектор весов $w$. То есть, чтобы выполнялось матричное уравнение:\n",
    "$$\\Large y = Xw$$\n",
    "Домножением слева на $X^T$ получаем:\n",
    "$$\\Large X^Ty = X^TXw$$\n",
    "Это хорошо, поскольку теперь матрица $X^TX$ - квадратная, и можно найти решение (вектор $w$) в виде:\n",
    "$$\\Large w = {(X^TX)}^{-1}X^Ty$$\n",
    "Матрица ${(X^TX)}^{-1}X^T$ - [*псевдообратная*](https://ru.wikipedia.org/wiki/Псевдообратная_матрица) для матрицы $X$. В NumPy такую матрицу можно вычислить с помощью функции [numpy.linalg.pinv](http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.linalg.pinv.html).\n",
    "\n",
    "Однако, нахождение псевдообратной матрицы - операция вычислительно сложная и нестабильная в случае малого определителя матрицы $X$ (проблема мультиколлинеарности). \n",
    "На практике лучше находить вектор весов $w$ решением матричного уравнения \n",
    "$$\\Large X^TXw = X^Ty$$Это может быть сделано с помощью функции [numpy.linalg.solve](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.linalg.solve.html).\n",
    "\n",
    "Но все же на практике для больших матриц $X$ быстрее работает градиентный спуск, особенно его стохастическая версия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инструкции по выполнению"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В начале напишем простую функцию для записи ответов в текстовый файл. Ответами будут числа, полученные в ходе решения этого задания, округленные до 3 знаков после запятой. Полученные файлы после выполнения задания надо отправить в форму на странице задания на Coursera.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_answer_to_file(answer, filename):\n",
    "    with open(filename, 'w') as f_out:\n",
    "        f_out.write(str(round(answer, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Загрузите данные из файла *advertising.csv* в объект pandas DataFrame. [Источник данных](http://www-bcf.usc.edu/~gareth/ISL/data.html).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "adver_data = pd.read_csv('advertising.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Посмотрите на первые 5 записей и на статистику признаков в этом наборе данных.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  Radio  Newspaper  Sales\n",
       "1  230.1   37.8       69.2   22.1\n",
       "2   44.5   39.3       45.1   10.4\n",
       "3   17.2   45.9       69.3    9.3\n",
       "4  151.5   41.3       58.5   18.5\n",
       "5  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adver_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>147.042500</td>\n",
       "      <td>23.264000</td>\n",
       "      <td>30.554000</td>\n",
       "      <td>14.022500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>85.854236</td>\n",
       "      <td>14.846809</td>\n",
       "      <td>21.778621</td>\n",
       "      <td>5.217457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>74.375000</td>\n",
       "      <td>9.975000</td>\n",
       "      <td>12.750000</td>\n",
       "      <td>10.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>149.750000</td>\n",
       "      <td>22.900000</td>\n",
       "      <td>25.750000</td>\n",
       "      <td>12.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>218.825000</td>\n",
       "      <td>36.525000</td>\n",
       "      <td>45.100000</td>\n",
       "      <td>17.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>296.400000</td>\n",
       "      <td>49.600000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TV       Radio   Newspaper       Sales\n",
       "count  200.000000  200.000000  200.000000  200.000000\n",
       "mean   147.042500   23.264000   30.554000   14.022500\n",
       "std     85.854236   14.846809   21.778621    5.217457\n",
       "min      0.700000    0.000000    0.300000    1.600000\n",
       "25%     74.375000    9.975000   12.750000   10.375000\n",
       "50%    149.750000   22.900000   25.750000   12.900000\n",
       "75%    218.825000   36.525000   45.100000   17.400000\n",
       "max    296.400000   49.600000  114.000000   27.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adver_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создайте массивы NumPy *X* из столбцов TV, Radio и Newspaper и *y* - из столбца Sales. Используйте атрибут *values* объекта pandas DataFrame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = adver_data.values[:, 0:3]\n",
    "y = adver_data.values[:,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Отмасштабируйте столбцы матрицы *X*, вычтя из каждого значения среднее по соответствующему столбцу и поделив результат на стандартное отклонение. Для определенности, используйте методы mean и std векторов NumPy (реализация std в Pandas может отличаться).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 147.0425,   23.264 ,   30.554 ]),\n",
       " array([ 85.63933176,  14.80964564,  21.72410606]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = X.mean(axis=0)\n",
    "stds = X.std(axis=0)\n",
    "means, stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    X[:,i] = (X[:,i] - means[i])/stds[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Добавьте к матрице *X* столбец из единиц, используя методы *hstack*, *ones* и *reshape* библиотеки NumPy. Вектор из единиц нужен для того, чтобы не обрабатывать отдельно коэффициент $w_0$ линейной регрессии.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "n = len(X[:,0])\n",
    "ones = np.ones(n)\n",
    "ones = ones.reshape(n,1)\n",
    "X_new = np.hstack((ones, X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Реализуйте функцию *mserror* - среднеквадратичную ошибку прогноза. Она принимает два аргумента - объекты Series *y* (значения целевого признака) и *y\\_pred* (предсказанные значения). Не используйте в этой функции циклы - тогда она будет вычислительно неэффективной.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mserror(y, y_pred):\n",
    "    res = np.mean((y - y_pred)**2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales, если всегда предсказывать медианное значение Sales по исходной выборке? Запишите ответ в файл '1.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.34575\n"
     ]
    }
   ],
   "source": [
    "median = np.median(y)\n",
    "pred = np.array([median])\n",
    "y_pred = np.repeat(pred, n)\n",
    "answer1 = mserror(y, y_pred)\n",
    "print(answer1)\n",
    "write_answer_to_file(answer1, '1.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Реализуйте функцию *normal_equation*, которая по заданным матрицам (массивам NumPy) *X* и *y* вычисляет вектор весов $w$ согласно нормальному уравнению линейной регрессии.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normal_equation(x, y):\n",
    "    return np.dot(np.dot(np.linalg.inv(np.dot(x.T, x)), x.T), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 14.0225       3.91925365   2.79206274  -0.02253861]\n"
     ]
    }
   ],
   "source": [
    "norm_eq_weights = normal_equation(X_new, y)\n",
    "print(norm_eq_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какие продажи предсказываются линейной моделью с весами, найденными с помощью нормального уравнения, в случае средних инвестиций в рекламу по ТВ, радио и в газетах? (то есть при нулевых значениях масштабированных признаков TV, Radio и Newspaper). Запишите ответ в файл '2.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.0225\n"
     ]
    }
   ],
   "source": [
    "factors = np.array([1,0,0,0])\n",
    "answer2 = np.dot(factors, norm_eq_weights)\n",
    "print(answer2)\n",
    "write_answer_to_file(answer2, '2.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Напишите функцию *linear_prediction*, которая принимает на вход матрицу *X* и вектор весов линейной модели *w*, а возвращает вектор прогнозов в виде линейной комбинации столбцов матрицы *X* с весами *w*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_prediction(X, w):\n",
    "    prediction = np.dot(X, w)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales в виде линейной модели с весами, найденными с помощью нормального уравнения? Запишите ответ в файл '3.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.78412631451\n"
     ]
    }
   ],
   "source": [
    "y_predict = linear_prediction(X_new, norm_eq_weights)\n",
    "answer3 = mserror(y, y_predict)\n",
    "print(answer3)\n",
    "write_answer_to_file(answer3, '3.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Напишите функцию *stochastic_gradient_step*, реализующую шаг стохастического градиентного спуска для линейной регрессии. Функция должна принимать матрицу *X*, вектора *y* и *w*, число *train_ind* - индекс объекта обучающей выборки (строки матрицы *X*), по которому считается изменение весов, а также число *$\\eta$* (eta) - шаг градиентного спуска (по умолчанию *eta*=0.01). Результатом будет вектор обновленных весов. Наша реализация функции будет явно написана для данных с 3 признаками, но несложно модифицировать для любого числа признаков, можете это сделать.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stochastic_gradient_step(X, y, w, train_ind, eta=0.01):\n",
    "    x_ind = X[train_ind]\n",
    "    y_ind = y[train_ind]\n",
    "    tmp = np.dot(x_ind.T, (np.dot(x_ind, w.T) - y_ind)).T\n",
    "    grad = tmp / len(y)\n",
    "    return  w - 2*eta * grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Напишите функцию *stochastic_gradient_descent*, реализующую стохастический градиентный спуск для линейной регрессии. Функция принимает на вход следующие аргументы:**\n",
    "- X - матрица, соответствующая обучающей выборке\n",
    "- y - вектор значений целевого признака\n",
    "- w_init - вектор начальных весов модели\n",
    "- eta - шаг градиентного спуска (по умолчанию 0.01)\n",
    "- max_iter - максимальное число итераций градиентного спуска (по умолчанию 10000)\n",
    "- max_weight_dist - минимальное евклидово расстояние между векторами весов на соседних итерациях градиентного спуска,\n",
    "при котором алгоритм прекращает работу (по умолчанию 1e-8)\n",
    "- seed - число, используемое для воспроизводимости сгенерированных псевдослучайных чисел (по умолчанию 42)\n",
    "- verbose - флаг печати информации (например, для отладки, по умолчанию False)\n",
    "\n",
    "**На каждой итерации в вектор (список) должно записываться текущее значение среднеквадратичной ошибки. Функция должна возвращать вектор весов $w$, а также вектор (список) ошибок.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(X, y, w_init, eta=0.01, max_iter=1e5,\n",
    "                                min_weight_dist=1e-8, seed=42, verbose=False):\n",
    "    # Инициализируем расстояние между векторами весов на соседних\n",
    "    # итерациях большим числом. \n",
    "    weight_dist = np.inf\n",
    "    # Инициализируем вектор весов\n",
    "    w = w_init\n",
    "    # Сюда будем записывать ошибки на каждой итерации\n",
    "    errors = []\n",
    "    # Счетчик итераций\n",
    "    iter_num = 0\n",
    "    # Будем порождать псевдослучайные числа \n",
    "    # (номер объекта, который будет менять веса), а для воспроизводимости\n",
    "    # этой последовательности псевдослучайных чисел используем seed.\n",
    "    np.random.seed(seed)\n",
    "        \n",
    "    # Основной цикл\n",
    "    while weight_dist > min_weight_dist and iter_num < max_iter:\n",
    "        # порождаем псевдослучайный \n",
    "        # индекс объекта обучающей выборки\n",
    "        random_ind = np.random.randint(X.shape[0])\n",
    "        \n",
    "        w_cur = stochastic_gradient_step(X, y, w, random_ind)\n",
    "        weight_dist = np.sum(np.absolute(w - w_cur))\n",
    "        w = w_cur\n",
    "        y_predict = linear_prediction(X, w)\n",
    "        errors.append(mserror(y, y_predict))   \n",
    "        iter_num += 1\n",
    "        \n",
    "    return w, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Запустите $10^5$ итераций стохастического градиентного спуска. Укажите вектор начальных весов *w_init*, состоящий из нулей. Оставьте параметры  *eta* и *seed* равными их значениям по умолчанию (*eta*=0.01, *seed*=42 - это важно для проверки ответов).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w_init = np.array([0,0,0,0])\n",
    "stoch_grad_desc_weights, stoch_errors_by_iter = stochastic_gradient_descent(X_new, y, w_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим, чему равна ошибка на первых 50 итерациях стохастического градиентного спуска. Видим, что ошибка не обязательно уменьшается на каждой итерации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x9195a90>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEPCAYAAACHuClZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x6f77a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "plot(range(50), stoch_errors_by_iter[:50])\n",
    "xlabel('Iteration number')\n",
    "ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Теперь посмотрим на зависимость ошибки от номера итерации для $10^5$ итераций стохастического градиентного спуска. Видим, что алгоритм сходится.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x96aeef0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEPCAYAAACHuClZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHihJREFUeJzt3Xm0VNWZ9/HvA1dmZVAmmQUUHBBQBsVoGRX1ffOqSRyT\nTojGXt0xDq2ruwWTFUgPy5hO+m16MOkYp9iOrTFoliIYvNoxCiIgIEgwiMyIARTUIMPTf+xzpbjU\nnahhn6r6fdY6q3btOsNzq+re5+69z9nH3B0REZF8tIodgIiIlD8lExERyZuSiYiI5E3JRERE8qZk\nIiIieVMyERGRvBU1mZhZXzObY2ZvmtkSM7shqZ9qZuvMbEGyXJC1zRQzW2lmy81sYjHjExGRwrBi\nXmdiZr2AXu6+yMw6Aa8DFwNXADvc/Z/rrT8ceAgYA/QFngeGui6GERFJtaK2TNx9k7svSso7geVA\nn+Rly7HJxcAj7r7H3VcDK4GxxYxRRETyV7IxEzMbCIwE5iZV15vZIjP7uZl1Tur6AGuzNlvP/uQj\nIiIpVZJkknRxPQ7clLRQ7gSOcfeRwCbgx6WIQ0REiqOm2AcwsxpCInnA3WcAuPuWrFXuAp5OyuuB\nflmv9U3q6u9TYygiIofA3XMNMeStFC2Te4Bl7j69riIZmK/zJWBpUn4KuNLM2pjZIGAIMC/XTt09\ndcvUqVOjx6CYFFM1xqWYmrcUU1FbJmY2AfgqsMTMFgIO3AZ8xcxGAvuA1cBfALj7MjN7DFgG7Aau\n82K/AyIikreiJhN3fxloneOlmY1scztwe9GCEhGRgtMV8AWUyWRih3AQxdQ8iqn50hiXYoqvqBct\nFouZqfdLRKSFzAwv4wF4ERGpcEomIiKSNyUTERHJm5KJiIjkTclERETypmQiIiJ5UzIREZG8KZmI\niEjelExERCRvSiYiIpI3JRMREcmbkomIiORNyURERPKmZCIiInlTMhERkbwpmYiISN6UTEREJG9K\nJiIikreyTSa6a6+ISHqUbTLZti12BCIiUqdsk8nmzbEjEBGROkomIiKSNyUTERHJm5KJiIjkrWyT\nyaZNsSMQEZE6ZZtM1DIREUkPJRMREcmbkomIiOStbJOJxkxERNLDvAznJTEzb9PG+dOfwCx2NCIi\n5cHMcPei/NUs25ZJhw6aUkVEJC3KNpn06qWuLhGRtCjbZNKnD6xfHzsKERGBMk8m69bFjkJERKDI\nycTM+prZHDN708yWmNmNSX1XM5tlZivM7Dkz65y1zRQzW2lmy81sYkP77ttXLRMRkbQodstkD3CL\nu58AnAZ828yGAZOB5939OGAOMAXAzI4HLgeGAxcCd5rlPl+rb1+1TERE0qKoycTdN7n7oqS8E1gO\n9AUuBu5PVrsfuCQpXwQ84u573H01sBIYm2vf6uYSEUmPko2ZmNlAYCTwKtDT3TdDSDhAj2S1PsDa\nrM3WJ3UHUTeXiEh61JTiIGbWCXgcuMndd5pZ/SslW3zl5MMPT2PFCpg2DTKZDJlMpgCRiohUjtra\nWmpra0tyrKJfAW9mNcCvgWfdfXpStxzIuPtmM+sFvODuw81sMuDufkey3kxgqrvPrbdP37vXad8e\nPvgA2rUr6o8gIlIRyv0K+HuAZXWJJPEU8I2kPAmYkVV/pZm1MbNBwBBgXq6dtmoFRx8NGzYUJ2gR\nEWm+onZzmdkE4KvAEjNbSOjOug24A3jMzK4B3iWcwYW7LzOzx4BlwG7gOm+k6VQ3CH/MMcX8KURE\npClFTSbu/jLQuoGXz21gm9uB25uzf50eLCKSDmV7BTwomYiIpEVZJxPNzyUikg5lnUzUMhERSYey\nTia6Cl5EJB3KOpnoKngRkXQo29v2uju7d0PHjvDxx1BTkmv5RUTKV7lftFg0hx0W7ri4dm3T64qI\nSPGUdTIBdXWJiKRB2ScTnR4sIhJf2SeT/v3h3XdjRyEiUt3KPpkMGABr1sSOQkSkupV9MtGYiYhI\nfGWfTPr00dlcIiKxlX0y6d9fyUREJLayvmgRYN8+6NABtm2D9u0jByYikmK6aLERrVpBv34ahBcR\nianskwnAwIHwzjuxoxARqV4VkUwGDNC1JiIiMVVEMhk4UMlERCSmikgmapmIiMRVMclk9erYUYiI\nVK+KSCbq5hIRiavsrzMB2Ls3XGuyfbuuNRERaYiuM2lC69bhWhO1TkRE4qiIZAIwaJCuNRERiaWi\nkokG4UVE4qioZKKWiYhIHBWTTDSliohIPBWTTNQyERGJp6KSicZMRETiqJhk0qMHfPIJ7NgROxIR\nkepTMcnETOMmIiKxVEwyAY2biIjEUnHJROMmIiKlV1HJRN1cIiJxFDWZmNndZrbZzBZn1U01s3Vm\ntiBZLsh6bYqZrTSz5WY2saXHUzeXiEgcxW6Z3Aucn6P+n919dLLMBDCz4cDlwHDgQuBOM2vR7JZK\nJiIicRQ1mbj7b4FtOV7KlSQuBh5x9z3uvhpYCYxtyfHqkkkZzqovIlLWYo2ZXG9mi8zs52bWOanr\nA6zNWmd9UtdsXbpATQ1s3VqoMEVEpDliJJM7gWPcfSSwCfhxIXc+aBCsWlXIPYqISFNqSn1Ad9+S\n9fQu4OmkvB7ol/Va36Qup2nTpn1WzmQyZDIZAAYPhrffhjFjChOviEi5qq2tpba2tiTHKvpte81s\nIPC0u5+UPO/l7puS8s3AGHf/ipkdDzwIjCN0b80GhnqOAOvftjfb5MnQqRN897vF+GlERMpXMW/b\nW9SWiZk9BGSAI81sDTAVONvMRgL7gNXAXwC4+zIzewxYBuwGrmswYzRi8GB45ZXCxC8iIs1T9JZJ\nMTTWMpkzB77/fXjxxRIHJSKScsVsmVTUFfAQWiZ/+EPsKEREqkvFtUz27oWOHWH7dmjXrsSBiYik\nmFomLdC6NfTvryvhRURKqeKSCairS0Sk1JRMREQkbxWZTIYOhZUrY0chIlI9KjKZHHccvPVW7ChE\nRKpHRSaT4cNh+fLYUYiIVI+KTCb9+oVTgz/8MHYkIiLVoSKTSatWMGwYLFsWOxIRkerQaDIxsz/L\nKk+o99r1xQqqEEaMgMWLm15PRETy11TL5Jas8r/Ve+2aAsdSUCefrGQiIlIqTSUTa6Cc63mqjBgB\nb7wROwoRkerQVDLxBsq5nqfKyJEhmezbFzsSEZHK19T9TIaZ2WJCK2RwUiZ5fkxRI8tTt27QuTOs\nXg3HpDpSEZHy11QyGV6SKIrkhBNg6VIlExGRYmu0m8vd381egJ3AaOCo5HmqaRBeRKQ0mjo1+Ndm\ndmJS7g0sJZzF9YCZ/VUJ4svLqFGwYEHsKEREKl9TA/CD3H1pUr4amO3u/w8YR8pPDYZwRtfSpU2v\nJyIi+WkqmezOKp8DPAPg7juA1J8nNWQIrF0LH38cOxIRkcrWVDJZa2Y3mNkXCWMlMwHMrD1wWLGD\ny1ebNmHSxyVLYkciIlLZmkom3wROAL4BXOHu25P68cC9RYyrYEaNgoULY0chIlLZGj012N3fA/4y\nR/0LwAvFCqqQTjxR4yYiIsXWaDIxs6cae93dLypsOIV30knwq1/FjkJEpLKZe8OzopjZFmAt8DAw\nl3rzcbn7i0WNruG4vLG4s/3xj+GixW3bwtT0IiLVysxw96LMq9jUn9dewG3AicB04DzgfXd/MVYi\naakjj4QuXWDVqtiRiIhUrqaugN/r7jPdfRJh0P1toDbt9zKpT4PwIiLF1WTHj5m1NbMvAf8FfBv4\nV+DJYgdWSCNHKpmIiBRTUwPwvyB0cT0DfD/raviycsop8O//HjsKEZHK1dQA/D7go+Rp9ooGuLsf\nUcTYGtSSAXiADRvC1CpbtoCl+pZeIiLFU8wB+KauM6mI859694bDDoM1a2DAgNjRiIhUnopIFk0x\ng1NPhddfjx2JiEhlqopkAiGZvPZa7ChERCqTkomIiOStapLJqFHwxhvQgnF7ERFppqpJJr17Q01N\nGIQXEZHCKmoyMbO7zWyzmS3OqutqZrPMbIWZPWdmnbNem2JmK81suZlNLGwsMGaMurpERIqh2C2T\ne4Hz69VNBp539+OAOcAUADM7HrgcGA5cCNxpVtirQpRMRESKo6jJxN1/C2yrV30xcH9Svh+4JClf\nBDzi7nvcfTWwEhhbyHjGjoV58wq5RxERgThjJj3cfTOAu28CeiT1fQjT3ddZn9QVzJgx4VqTvXsL\nuVcREUnDAHzJzq/q1g169YJly0p1RBGR6tDodCpFstnMerr7ZjPrBbyX1K8H+mWt1zepy2natGmf\nlTOZDJlMplkHP/VUWLAg3IFRRKSS1dbWUltbW5JjNTrRY0EOYDYQeNrdT0qe3wFsdfc7zOxWoKu7\nT04G4B8ExhG6t2YDQ3PN6NjSiR6z/fCHsH49TJ9+SJuLiJStmHdazIuZPQT8DjjWzNaY2dXAD4Dz\nzGwFcE7yHHdfBjwGLCNMeX/dIWeMRowbB3PnFnqvIiLVregtk2LIp2Xy0UfQowds3Qpt2xY4MBGR\nFCvblkkadewIQ4fCokWxIxERqRxVl0wAxo9XV5eISCFVZTIZNw5efTV2FCIilaMqk8kZZ8CLL2oG\nYRGRQqnKZDJkSJj48e23Y0ciIlIZqjKZmMF558Hs2bEjERGpDFWZTADOPBNeeil2FCIilaHqk4nG\nTURE8ld1Fy3WcQ93XlyxIoyhiIhUOl20WARmcNZZOkVYRKQQqjaZAHz5yxqEFxEphKrt5gJYswZO\nOQU2bYLWrQsQmIhIiqmbq0j694eePWH+/NiRiIiUt6pOJgDnnANz5sSOQkSkvFV9Mjn3XCUTEZF8\nVfWYCcCHH0KfPmHcpGPHguxSRCSVNGZSREccASNG6BRhEZF8VH0yATj7bPjNb2JHISJSvpRMgIkT\nYebM2FGIiJQvJRPg9NNh7Vp4993YkYiIlCclE8IcXeefD889FzsSEZHypGSSmDhRyURE5FBV/anB\ndbZsCbMHv/cetG1b0F2LiKSCTg0uge7d4eST1ToRETkUSiZZrrwSHn44dhQiIuVH3VxZtmyBoUNh\n40Zo377guxcRiUrdXCXSvTuMHq2uLhGRllIyqeeyy+DRR2NHISJSXtTNVU/dWV0bNmjiRxGpLOrm\nKqHu3WH8ePj1r2NHIiJSPpRMcvj61+G++2JHISJSPtTNlcPHH0PfvrBkSbjXiYhIJVA3V4l16ACX\nXgq/+EXsSEREyoNaJg2YNy9cxPj229BKKVdEKoBaJhGMGQOdOsFLL8WOREQk/ZRMGmAGkyZpIF5E\npDmidXOZ2WrgA2AfsNvdx5pZV+BRYACwGrjc3T/IsW3Ru7kANm+G446DNWvCveJFRMpZpXZz7QMy\n7j7K3ccmdZOB5939OGAOMCVadEDPnnDuufDggzGjEBFJv5jJxHIc/2Lg/qR8P3BJSSPK4Vvfgp/8\nBMrwPAURkZKJmUwcmG1mr5nZtUldT3ffDODum4Ae0aJLnH027NqlgXgRkcbURDz2BHffaGbdgVlm\ntoKQYLI12B6YNm3aZ+VMJkMmkylGjLRqBX/913DHHXDWWUU5hIhIUdTW1lJbW1uSY6XiOhMzmwrs\nBK4ljKNsNrNewAvuPjzH+iUZgK/zyScwcCD85jdw4oklO6yISEFV3AC8mXUws05JuSMwEVgCPAV8\nI1ltEjAjRnz1tW8fWif/8A+xIxERSacoLRMzGwQ8SejGqgEedPcfmFk34DGgH/Au4dTg7Tm2L2nL\nBGDHjtA6ef318CgiUm6K2TJJRTdXS8VIJgBTpsC2bfDTn5b80CIieVMyqSdWMvnjH8NFjHPnwuDB\nJT+8iEheKm7MpFwdeSTcdBN873uxIxERSRe1TFpoxw4YOhRmzYIRI6KEICJySNQySZHDDw9jJ9/5\nTuxIRETSQy2TQ7BrFxx7LDz0EEyYEC0MEZEWUcskZdq2hb/7O7jlFti7N3Y0IiLxKZkcoq99Ddq1\ngzvvjB2JiEh86ubKw/LlcOaZMH8+DBgQOxoRkcapmyulhg+HG2+E66/XFPUiUt2UTPJ0662wbh38\n7GexIxERiUfdXAXw1ltwxhnw8svhCnkRkTRSN1fKDRsGf//3cNVV4bRhEZFqo5ZJgbjDF78IQ4bA\nj34UOxoRkYNposd60phMAN5/H0aNgp//HM4/P3Y0IiIHUjdXmTjqKLj/frj6anjvvdjRiIiUjpJJ\ngX3+83DNNXDRRfDhh7GjEREpDXVzFYE7XHcdLF0KM2dCx46xIxIR0ZjJQdKeTAD27YNJk2D7dnj8\n8TCfl4hITBozKUOtWsHdd0ObNnDJJbBzZ+yIRESKR8mkiNq0gUcfhV69YOJE2Lo1dkQiIsWhZFJk\nNTVwzz1w+ulhUsg1a2JHJCJSeEomJWAWLmS85ho47TSYOzd2RCIihaVkUkK33AI//Sl84Qtw332a\naVhEKofO5opg6VK4/HIYNw6mT4cjjogdkYhUA53NVWFOPBHmzQvjKccfDzNmxI5IRCQ/aplE9tJL\ncO21cOqpoZXSvXvsiESkUqllUsHOPBPeeAN69w4tlv/8T9izJ3ZUIiIto5ZJiixaBDffDBs2wA03\nwDe/Ce3bx45KRCqFWiZVYuRImDMH7roLZs+GQYPgH/9RMxCLSPopmaSMWej6mjEDnn8eVq0KtwK+\n7DJ49lnYuzd2hCIiB1M3VxnYvh0eeSRcSb9xI1xxBVx6KYwdG+YAExFpDs0aXE+1JZNsS5fCY4/B\nE0+EOztecAFceGGY+6tbt9jRiUiaKZnUU83JJNs774T7pTzzDLz4Yrj//GmnhYshR4+GYcPCtSwi\nIqBkchAlk4N9+inMnw+vvBIeFy6EdevgpJNCYhkxAgYPhmOOgX794LDDYkcsIqWmZFKPkknz7NgR\nTjdesACWLAmD+atWhXGXo48OiaVuGTRof/nII8OJACJSWaoumZjZBcC/EM42u9vd76j3upJJHnbv\nDlPh1yWXd97ZX161Krzev3+4Gv+oo8LSrRt07QpdukDnzmE+sU6d4PDD9y+dOkG7dkpEImlVVcnE\nzFoBvwfOATYArwFXuvtbWeukMpnU1taSyWRih3GAQ4lp+/bQRfb++7BlS1i2bg3127bBBx+EVk/d\nsnPn/vKePdChQ7jvfceO4XbF7dqFx7plx45a+vTJfFbfpg20bh2WmpqDyy2pa9Vq/2J24AINPy5Z\nUsuIEZmD6hvbpqHHQ9km17YLF9YyevTBMeVzvEKYP7+WU0/NFG6HBRArpsbe10LENGxY+P0plGIm\nkzQOz44FVrr7uwBm9ghwMfBWo1ulQKUkky5dwnIo9uyBjz+Gjz4Ky5/+BLt2Hbjcd18tX/pS5rPX\nPv00XD9Tt+zZc+Djp5/uL+d6va68Zw/s2xem9t+7NzzWLdD44+9/X8vQoZkD6pvaJtfjoWzT0LZr\n19bSt2+mRds0tW4hbNxYS+/emcLuNE8xYmrqfd20qZZevTJ5HeOJJ8JYZzlIYzLpA6zNer6OkGCk\nDNTUhC6wxqbVf/XVMAV/mkybFpY0SWNMkM64FFN8uuRNRETylsYxk/HANHe/IHk+GfDsQXgzS1fQ\nIiJlopoG4FsDKwgD8BuBecBV7r48amAiItKg1I2ZuPteM7semMX+U4OVSEREUix1LRMRESlD7l5W\nC3AB4TTh3wO3FmH/dwObgcVZdV0JLaUVwHNA56zXpgArgeXAxKz60cDiJM5/yapvAzySbPMK0L8Z\nMfUF5gBvAkuAG2PHBbQF5gILk5imxo4pa7tWwALgqTTEBKwG3kjeq3kpiakz8N/JMd4ExqUgpmOT\n92hB8vgBcGMK4roZWJrs78FkH7Fjuonwe5eKvwfuXl7JhPBH4m1gAHAYsAgYVuBjnAGM5MBkcgfw\nt0n5VuAHSfn45EtfAwxMYqtr7c0FxiTlZ4Dzk/K3gDuT8hXAI82IqRcwMil3Sr4sw1IQV4fksTXw\nKuEU7qgxJeveDPwX+5NJ7PdpFdC1Xl3smO4Drk7KNYTkEv2zq/e7vgHoFzMu4Ojk82uTPH8UmBQ5\nphMICaAt4XdvFjA49ucXPUG08As2Hng26/lkitM6GcCByeQtoGdS7gW8lev4wLOE//B6Acuy6q8E\nfpKUZwLjknJrYMshxPcr4Ny0xAV0AOYDY2LHRGjFzQYy7E8msWN6BziyXl20mIAjgD/kqE/F9ynZ\nZiLwP7HjIiSTdwn/9dcATxH5dw+4FLgr6/l3gb8htDqifX7ldp1Jrgsa+5TguD3cfTOAu28CejQQ\nz/qkrk8SW644P9vG3fcC282s2XciMbOBhJbTq4QvTrS4zKyVmS0ENgGz3f212DEB/5/wi+VZdbFj\ncmC2mb1mZtemIKZBwPtmdq+ZLTCzn5lZh8gx1XcF8FBSjhaXu28AfgysSfb/gbs/HzMmQpfb58ys\na/K5/R9CCy7q51duySQtvOlVmq3Z53ybWSfgceAmd9+ZI46SxuXu+9x9FKE1MNbMTogZk5n9X2Cz\nuy9qYt1Sf34T3H004Zf+22b2uRwxlDKmGkJf+X8kcX1E+O816vfpsxXNDgMuIozp5IqjlN+pLoTp\nnAYQWikdzeyrMWPyME/hHYQW+DOELqxcN/Qu6edXbslkPdA/63nfpK7YNptZTwAz6wW8lxVPvxzx\nNFR/wDbJNTVHuPvWpgIwsxpCInnA3WekJS4Ad/8QqCWcHBEzpgnARWa2CngY+LyZPQBsivk+ufvG\n5HELoYtyLHHfp3XAWnefnzx/gpBcUvF9Ai4EXnf395PnMeM6F1jl7luT/9CfBE6PHBPufq+7n+ru\nGWA7YRw1akzllkxeA4aY2QAza0Po43uqCMcxDszETwHfSMqTgBlZ9VeaWRszGwQMIZytswn4wMzG\nmpkBX6+3zaSkfBnhLK3muIfQvzk9DXGZ2VFm1jkptwfOI/TZRovJ3W9z9/7ufgzhuzHH3b8GPB3x\nfeqQtCgxs46EsYAlkd+nzcBaMzs2qTqHcEZXGr7nAFcR/hmoEzOuNcB4M2uX7OscYFnkmDCz7slj\nf+CLhC7BuJ9fU4MqaVsI//2uIJyyNrkI+3+IcBbJLsIX6WrC4NvzyXFnAV2y1p9CODui/il3pxD+\naKwEpmfVtwUeS+pfBQY2I6YJhGbsIvafOnkB0C1WXMBJSRyLCGeWfCepjxZTvfjOYv8AfMz3aVDW\n57ak7jsb+30CTib8c7YI+CXhbK7onx3hZI4twOFZdbHfq6nJ/hcD9xPOJI0d00uEsZOFQCYN75Mu\nWhQRkbyVWzeXiIikkJKJiIjkTclERETypmQiIiJ5UzIREZG8KZmIiEjelEykrJjZjuRxgJldVeB9\nT6n3/LeF3H+hmdkkM/u32HGIgJKJlJ+6C6MGAV9pyYbJtBCNue2AA7mf0ZL9R3LIF4qZmX7/pWD0\nZZJydTtwRjLr7U3JDMY/NLO5ZrbIzP4cwMzOMrOXzGwGYcoQzOxJCzP4LrFkFl8zux1on+zvgaRu\nR93BzOyfkvXfMLPLs/b9gpn9t5ktr9uuvmSdHySxvWVmE5L6A1oWZva0mZ1Zd+zk51lqZrPMbEyy\nn7fN7AtZu++f1K8ws+9l7euryfEWmNlPkuky6vb7IwuzPY/P+1MQqdPc6Sm0aEnDAnyYPH42XUry\n/M+B25JyG8JUIQOS9XaQdac4kmkmgHaEqSS6Zu87x7G+DDyXlHsQ7m/RM9n3NqA3YS633wGn54j5\nBeCfkvKFhOn6Icx99K9Z6z0NnJmU95FMe0GY7mQm4Z+/EcDCrO3XA12yfpbRhBunPQW0Ttb7D+DP\nsvb75difo5bKW2oOMQeJpM1E4CQzuyx5fgQwFNhNmNRuTda6f2VmlyTlvsl68xrZ9wSSiQfd/T0z\nqyXcCGxHsu+NAGa2iHAnu9/l2Mcvk8fXCUmuKbvcfVZSXgL8yd33mdmSetvPdvftyfGfINwpdC9h\nzqXXkhZJO8I9Z0he+yUiBaZkIpXCgBvcffYBlWZnEe7Xkf3884S7yO0ysxcIf2zr9tHcY9XZlVXe\nS8O/U7tyrLOHA7ua22WVd2eV99Vt7+5u4XYEdbLHTCzr+X3u/p0ccXzi7pqQTwpOYyZSbur+kO8A\nDs+qfw64ru4PrZkNtXAXuvo6A9uSRDKMA8cNPq33h7ruWP8DXJGMy3QHPkfjLZnm/gyrgZEW9CPc\n56T+Oo1tD3CemXWxcBuAS4CXCdOFX5o1TXnXZP9N7VfkkKllIuWm7r/qxcC+ZCD5PnefbuGWxguS\nrp33CH9c65sJ/KWZvUmYqvuVrNd+Biw2s9c93AfFAdz9STMbD7xBaCX8TdLdNbyB2BqK+YDn7v6y\nma0mnBiwnNAF1tS+6r82j9Bt1Ydw47QFAGb2XWBWcsbWp8C3CbdhVatEikJT0IuISN7UzSUiInlT\nMhERkbwpmYiISN6UTEREJG9KJiIikjclExERyZuSiYiI5E3JRERE8va/B1upyqdwfcYAAAAASUVO\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x8f74320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "plot(range(len(stoch_errors_by_iter)), stoch_errors_by_iter)\n",
    "xlabel('Iteration number')\n",
    "ylabel('MSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84501"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stoch_errors_by_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на вектор весов, к которому сошелся метод.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.40190566e+01   3.91069256e+00   2.78209808e+00  -8.10462217e-03]\n",
      "[ 14.0225       3.91925365   2.79206274  -0.02253861]\n"
     ]
    }
   ],
   "source": [
    "print(stoch_grad_desc_weights)\n",
    "print(norm_eq_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на среднеквадратичную ошибку на последней итерации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7844125884067035"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoch_errors_by_iter[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales в виде линейной модели с весами, найденными с помощью градиентного спуска? Запишите ответ в файл '4.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.78441258841\n",
      "2.78412631451\n"
     ]
    }
   ],
   "source": [
    "y_predict_grad = linear_prediction(X_new, stoch_grad_desc_weights)\n",
    "answer4 = mserror(y, y_predict_grad)\n",
    "print(answer4)\n",
    "print(answer3)\n",
    "write_answer_to_file(answer4, '4.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответами к заданию будут текстовые файлы, полученные в ходе этого решения. Обратите внимание, что отправленные файлы не должны содержать пустую строку в конце. Данный нюанс является ограничением платформы Coursera. Мы работаем над исправлением этого ограничения.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
